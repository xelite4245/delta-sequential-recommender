{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af0a92da",
   "metadata": {},
   "source": [
    "# Personalized Workout Progression System: Model Workflow\n",
    "## User2 Squat Example\n",
    "\n",
    "This notebook demonstrates the complete workflow of the Personalized Workout Progression System:\n",
    "1. Load User2's training history\n",
    "2. Train (or load) a global squat model\n",
    "3. Generate raw predictions\n",
    "4. Apply per-user calibration\n",
    "5. Compare with rule-based fallback\n",
    "6. Log to SQLite\n",
    "7. Visualize periodization cycles and calibration\n",
    "\n",
    "**Target User**: Intermediate/advanced lifters with established periodization patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add repo root to path for imports\n",
    "repo_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sqlite3\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "print(f\"‚úì Repo root: {repo_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aadc6e",
   "metadata": {},
   "source": [
    "## 1. Load User2's Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f2e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_path = repo_root / \"data\" / \"user_inputs\" / \"user2_squat_history.csv\"\n",
    "fut_path = repo_root / \"data\" / \"user_inputs\" / \"user2_squat_future.csv\"\n",
    "\n",
    "history = pd.read_csv(hist_path)\n",
    "future = pd.read_csv(fut_path)\n",
    "\n",
    "print(f\"History: {len(history)} rows, {len(history.columns)} columns\")\n",
    "print(f\"Future:  {len(future)} rows, {len(future.columns)} columns\")\n",
    "print(f\"\\nHistory columns: {list(history.columns)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(history.head())\n",
    "print(f\"\\nLast 5 rows:\")\n",
    "print(history.tail())\n",
    "print(f\"\\nFuture (next session to predict):\")\n",
    "print(future)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da9a8a1",
   "metadata": {},
   "source": [
    "## 2. Analyze Training Pattern & Periodization Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58633fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract last weight in history\n",
    "last_weight = history.iloc[-1]['weight']\n",
    "last_reps = history.iloc[-1]['reps']\n",
    "max_weight = history['weight'].max()\n",
    "\n",
    "print(f\"User2 Squat Statistics:\")\n",
    "print(f\"  Current weight: {last_weight} lbs\")\n",
    "print(f\"  Current reps: {last_reps}\")\n",
    "print(f\"  Max weight ever: {max_weight} lbs\")\n",
    "print(f\"  Weight range: {history['weight'].min()} - {max_weight} lbs\")\n",
    "print(f\"  Training sessions: {len(history)}\")\n",
    "\n",
    "# Analyze load_delta pattern (last 20)\n",
    "print(f\"\\nLast 20 load_delta changes:\")\n",
    "deltas = history['load_delta'].tail(20).values\n",
    "for i, delta in enumerate(deltas, 1):\n",
    "    sign = \"‚Üë\" if delta > 0 else \"‚Üì\" if delta < 0 else \"‚Üí\"\n",
    "    print(f\"  {i:2d}: {sign} {delta:+.1f} lbs\")\n",
    "\n",
    "# Detect cycles (15% drop = deload)\n",
    "hist_copy = history.copy()\n",
    "prev_weight = hist_copy['weight'].shift(1)\n",
    "pct_change = (prev_weight - hist_copy['weight']) / prev_weight\n",
    "hist_copy['is_deload'] = pct_change >= 0.15\n",
    "hist_copy['cycle_number'] = hist_copy['is_deload'].cumsum()\n",
    "hist_copy['weeks_in_cycle'] = hist_copy.groupby('cycle_number').cumcount() + 1\n",
    "\n",
    "n_deloads = hist_copy['is_deload'].sum()\n",
    "current_cycle = hist_copy.iloc[-1]['cycle_number']\n",
    "weeks_in = hist_copy.iloc[-1]['weeks_in_cycle']\n",
    "pct_of_max = (last_weight / max_weight) * 100\n",
    "\n",
    "print(f\"\\nPeriodization Analysis (15% drop threshold):\")\n",
    "print(f\"  Total deloads detected: {n_deloads}\")\n",
    "print(f\"  Current cycle: #{current_cycle}\")\n",
    "print(f\"  Weeks in current cycle: {weeks_in}\")\n",
    "print(f\"  Current: {pct_of_max:.1f}% of max\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b67321",
   "metadata": {},
   "source": [
    "## 3. Load Trained Global Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef66a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = repo_root / \"models\" / \"compounds\" / \"squat_model.pkl\"\n",
    "\n",
    "if not model_path.exists():\n",
    "    print(f\"‚ö† Model not found at {model_path}\")\n",
    "    print(\"Please run: python -m src.cli train-compounds\")\n",
    "else:\n",
    "    # Load model\n",
    "    model_obj = joblib.load(model_path)\n",
    "    \n",
    "    # Extract pipeline if saved via BaseModel.save()\n",
    "    if isinstance(model_obj, dict):\n",
    "        pipe = model_obj.get('pipeline')\n",
    "        metadata = model_obj.get('metadata', {})\n",
    "    else:\n",
    "        pipe = model_obj\n",
    "        metadata = {}\n",
    "    \n",
    "    print(\"‚úì Model loaded successfully\")\n",
    "    print(f\"  Model type: {type(pipe).__name__}\")\n",
    "    print(f\"  Metadata: {metadata}\")\n",
    "    \n",
    "    # Show pipeline steps\n",
    "    if hasattr(pipe, 'named_steps'):\n",
    "        print(f\"\\n  Pipeline steps:\")\n",
    "        for name, step in pipe.named_steps.items():\n",
    "            print(f\"    - {name}: {step.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777a0ec0",
   "metadata": {},
   "source": [
    "## 4. Generate Raw Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97448d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate raw prediction\n",
    "raw_pred = pipe.predict(future)\n",
    "raw_delta = float(raw_pred[0])\n",
    "predicted_weight = last_weight + raw_delta\n",
    "\n",
    "print(f\"Raw Model Prediction:\")\n",
    "print(f\"  load_delta: {raw_delta:+.2f} lbs\")\n",
    "print(f\"  Next weight: {last_weight} + ({raw_delta:.2f}) = {predicted_weight:.2f} lbs\")\n",
    "print(f\"  Change: {'‚Üë increase' if raw_delta > 0 else '‚Üì decrease' if raw_delta < 0 else '‚Üí hold'}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  Model suggests: {predicted_weight:.1f} lbs\")\n",
    "print(f\"  This is based on PPL data (135-425 lbs lifters)\")\n",
    "print(f\"  User2 scale: 45-75 lbs (beginner progression)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b47cd3",
   "metadata": {},
   "source": [
    "## 5. Apply Per-User Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load User2's personalization (calibration)\n",
    "pers_path = repo_root / \"users\" / \"User2\" / \"personalization.json\"\n",
    "\n",
    "if pers_path.exists():\n",
    "    with open(pers_path) as f:\n",
    "        personalization = json.load(f)\n",
    "    \n",
    "    a = personalization['scaling_factors']['squat']\n",
    "    b = personalization['baseline_offsets']['squat']\n",
    "    meta = personalization['calibration_meta']['squat']\n",
    "    \n",
    "    # Apply calibration\n",
    "    adjusted_delta = a * raw_delta + b\n",
    "    adjusted_weight = last_weight + adjusted_delta\n",
    "    \n",
    "    print(f\"User2 Personalization Found:\")\n",
    "    print(f\"  Calibration (a, b): ({a:.3f}, {b:.3f})\")\n",
    "    print(f\"  Calibration history: {meta['last_calibrated_size']} rows, {meta['runs']} fit(s)\")\n",
    "    \n",
    "    print(f\"\\nCalibration Transform:\")\n",
    "    print(f\"  adjusted = a √ó raw + b\")\n",
    "    print(f\"  adjusted = {a:.3f} √ó {raw_delta:.2f} + {b:.3f}\")\n",
    "    print(f\"  adjusted = {adjusted_delta:.2f} lbs\")\n",
    "    \n",
    "    print(f\"\\nAdjusted Prediction:\")\n",
    "    print(f\"  load_delta: {adjusted_delta:+.2f} lbs\")\n",
    "    print(f\"  Next weight: {last_weight} + ({adjusted_delta:.2f}) = {adjusted_weight:.2f} lbs\")\n",
    "    \n",
    "    print(f\"\\nComparison:\")\n",
    "    print(f\"  Raw model:     {predicted_weight:.2f} lbs\")\n",
    "    print(f\"  After calib:   {adjusted_weight:.2f} lbs\")\n",
    "    print(f\"  Difference:    {adjusted_weight - predicted_weight:+.2f} lbs\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö† No personalization found for User2\")\n",
    "    print(\"  This is the first prediction, or calibration hasn't been run yet\")\n",
    "    adjusted_delta = raw_delta\n",
    "    adjusted_weight = predicted_weight\n",
    "    a, b = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80cf586",
   "metadata": {},
   "source": [
    "## 6. Compare with Rule-Based Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4df67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import rule-based module\n",
    "from src.rule_based import rule_based_progression\n",
    "\n",
    "# Get last session info\n",
    "last_row = history.iloc[-1]\n",
    "last_weight_val = float(last_row['weight'])\n",
    "last_reps_val = float(last_row['reps'])\n",
    "last_rpe = float(last_row['rpe']) if 'rpe' in last_row.index and pd.notna(last_row['rpe']) else 7.0\n",
    "\n",
    "# Run rule-based\n",
    "sugg = rule_based_progression(last_weight=last_weight_val, last_reps=last_reps_val, last_rpe=last_rpe)\n",
    "\n",
    "print(f\"Rule-Based Fallback (Last Session: {last_weight_val} lbs √ó {last_reps_val} reps @ RPE {last_rpe:.1f}):\")\n",
    "print(f\"  Suggested weight: {sugg.suggested_weight:.2f} lbs\")\n",
    "print(f\"  Reason: {sugg.reason}\")\n",
    "\n",
    "print(f\"\\n3-Way Comparison:\")\n",
    "print(f\"  {'Method':<20} {'Next Weight':<15} {'Delta':<10}\")\n",
    "print(f\"  {'-'*45}\")\n",
    "print(f\"  {'Rule-based':<20} {sugg.suggested_weight:<15.2f} {sugg.suggested_weight - last_weight_val:+.2f}\")\n",
    "print(f\"  {'ML (raw)':<20} {predicted_weight:<15.2f} {raw_delta:+.2f}\")\n",
    "print(f\"  {'ML (calibrated)':<20} {adjusted_weight:<15.2f} {adjusted_delta:+.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd83c69",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Pattern & Periodization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aefa838",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Weight over time\n",
    "ax = axes[0, 0]\n",
    "ax.plot(range(len(history)), history['weight'], marker='o', markersize=3, label='Weight', alpha=0.7)\n",
    "ax.scatter(len(history)-1, last_weight, color='blue', s=100, zorder=5, label='Current')\n",
    "ax.axhline(max_weight, color='green', linestyle='--', alpha=0.5, label='Max')\n",
    "ax.set_xlabel('Session')\n",
    "ax.set_ylabel('Weight (lbs)')\n",
    "ax.set_title('Weight Progression Over Time')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Load delta distribution\n",
    "ax = axes[0, 1]\n",
    "deltas = history['load_delta'].dropna()\n",
    "ax.bar(range(len(deltas)), deltas, color=['green' if d >= 0 else 'red' for d in deltas], alpha=0.6)\n",
    "ax.axhline(0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax.set_xlabel('Session (chronological)')\n",
    "ax.set_ylabel('load_delta (lbs)')\n",
    "ax.set_title('Load Changes by Session')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Reps vs Weight scatter\n",
    "ax = axes[1, 0]\n",
    "scatter = ax.scatter(history['weight'], history['reps'], c=range(len(history)), cmap='viridis', s=50, alpha=0.6)\n",
    "ax.set_xlabel('Weight (lbs)')\n",
    "ax.set_ylabel('Reps')\n",
    "ax.set_title('Weight √ó Reps (colored by time)')\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Session #')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Cycle detection (last 50 sessions)\n",
    "ax = axes[1, 1]\n",
    "tail_n = min(50, len(hist_copy))\n",
    "tail_data = hist_copy.tail(tail_n).reset_index(drop=True)\n",
    "colors = ['red' if d else 'blue' for d in tail_data['is_deload']]\n",
    "ax.bar(range(len(tail_data)), tail_data['weeks_in_cycle'], color=colors, alpha=0.6)\n",
    "ax.set_xlabel('Session (last 50)')\n",
    "ax.set_ylabel('Weeks in Cycle')\n",
    "ax.set_title('Periodization Cycles (red=deload, blue=climb)')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualizations complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6655ebb2",
   "metadata": {},
   "source": [
    "## 8. SQLite Logging (Predictions & Calibrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03dd9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = repo_root / \"data\" / \"user_data.db\"\n",
    "\n",
    "if db_path.exists():\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    \n",
    "    print(\"=== PREDICTIONS TABLE ===\")\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT user_id, compound, session_index, predicted_raw, predicted_adjusted, source, created_at\n",
    "        FROM predictions\n",
    "        WHERE user_id = 'User2' AND compound = 'squat'\n",
    "        ORDER BY created_at DESC\n",
    "        LIMIT 5\n",
    "    \"\"\")\n",
    "    \n",
    "    preds = cur.fetchall()\n",
    "    print(f\"Latest 5 predictions for User2/squat:\\n\")\n",
    "    for row in preds:\n",
    "        raw_str = f\"{row['predicted_raw']:.2f}\" if row['predicted_raw'] is not None else \"NULL\"\n",
    "        adj_str = f\"{row['predicted_adjusted']:.2f}\" if row['predicted_adjusted'] is not None else \"NULL\"\n",
    "        print(f\"  {row['created_at'][:19]}\")\n",
    "        print(f\"    Raw: {raw_str} lbs ‚Üí Adj: {adj_str} lbs | Source: {row['source']}\")\n",
    "    \n",
    "    print(f\"\\n=== CALIBRATIONS TABLE ===\")\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT user_id, compound, a, b, last_calibrated_size, runs, updated_at\n",
    "        FROM calibrations\n",
    "        WHERE user_id = 'User2' AND compound = 'squat'\n",
    "    \"\"\")\n",
    "    \n",
    "    calib = cur.fetchone()\n",
    "    if calib:\n",
    "        print(f\"User2/squat calibration:\")\n",
    "        print(f\"  a (gain):  {calib['a']:.4f}\")\n",
    "        print(f\"  b (offset): {calib['b']:.4f}\")\n",
    "        print(f\"  Last calibrated size: {calib['last_calibrated_size']}\")\n",
    "        print(f\"  Fit runs: {calib['runs']}\")\n",
    "        print(f\"  Updated: {calib['updated_at']}\")\n",
    "    else:\n",
    "        print(\"No calibration found in DB for User2/squat\")\n",
    "    \n",
    "    conn.close()\n",
    "else:\n",
    "    print(\"‚ö† Database not found at\", db_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c023f99b",
   "metadata": {},
   "source": [
    "## 9. Full Personalization JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61da581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pers_path = repo_root / \"users\" / \"User2\" / \"personalization.json\"\n",
    "\n",
    "if pers_path.exists():\n",
    "    with open(pers_path) as f:\n",
    "        pers_full = json.load(f)\n",
    "    \n",
    "    print(\"User2 Personalization (Full JSON):\")\n",
    "    print(json.dumps(pers_full, indent=2))\n",
    "    \n",
    "    print(\"\\n\\nInterpretation:\")\n",
    "    print(f\"‚Ä¢ scaling_factors: Gain multipliers per compound (1.0 = no change)\")\n",
    "    print(f\"‚Ä¢ baseline_offsets: Bias corrections per compound\")\n",
    "    print(f\"‚Ä¢ trend_modifiers: Future use for trend adaptation\")\n",
    "    print(f\"‚Ä¢ calibration_meta: Metadata on calibration refits\")\n",
    "    print(f\"\\nFormula: adjusted = a √ó raw + b\")\n",
    "    for compound in pers_full['scaling_factors']:\n",
    "        a = pers_full['scaling_factors'][compound]\n",
    "        b = pers_full['baseline_offsets'][compound]\n",
    "        if a != 1.0 or b != 0.0:\n",
    "            print(f\"  {compound}: adjusted = {a:.3f} √ó raw + {b:.4f}\")\n",
    "else:\n",
    "    print(\"No personalization JSON found for User2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec1c0ee",
   "metadata": {},
   "source": [
    "## 10. Summary & Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccacfc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"SUMMARY: User2 Squat Prediction Workflow\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä USER PROFILE\")\n",
    "print(f\"  Sessions logged: {len(history)}\")\n",
    "print(f\"  Weight range: {history['weight'].min():.0f} - {history['weight'].max():.0f} lbs\")\n",
    "print(f\"  Current: {last_weight:.0f} lbs √ó {last_reps:.0f} reps\")\n",
    "\n",
    "print(f\"\\nüîÑ PERIODIZATION\")\n",
    "print(f\"  Deloads detected (15% drop): {n_deloads}\")\n",
    "print(f\"  Current cycle: #{current_cycle}\")\n",
    "print(f\"  Weeks in cycle: {weeks_in}\")\n",
    "print(f\"  Distance from max: {100 - pct_of_max:.1f}% below peak\")\n",
    "\n",
    "print(f\"\\nü§ñ ML MODEL (Global)\")\n",
    "print(f\"  Training data: PPL (135-425 lbs lifters)\")\n",
    "print(f\"  Model type: Random Forest + FeatureEngineering + ColumnTransformer\")\n",
    "print(f\"  Raw prediction: {raw_delta:+.2f} lbs ‚Üí {predicted_weight:.2f} lbs\")\n",
    "\n",
    "if a is not None and b is not None:\n",
    "    print(f\"\\n‚öôÔ∏è USER CALIBRATION\")\n",
    "    print(f\"  Affine transform: adjusted = {a:.3f} √ó raw + {b:.4f}\")\n",
    "    print(f\"  Calibration on: {meta['last_calibrated_size']} recent sessions\")\n",
    "    print(f\"  Calibration runs: {meta['runs']}\")\n",
    "    print(f\"  Adjusted prediction: {adjusted_delta:+.2f} lbs ‚Üí {adjusted_weight:.2f} lbs\")\n",
    "    print(f\"  ‚úì Calibration reduces model's aggressive drop from {raw_delta:.1f} to {adjusted_delta:.1f}\")\n",
    "else:\n",
    "    print(f\"\\n‚öôÔ∏è USER CALIBRATION\")\n",
    "    print(f\"  ‚ö† Not yet calibrated (first run or insufficient history)\")\n",
    "    print(f\"  Minimum samples needed: 8\")\n",
    "    print(f\"  Current history: {len(history)} rows\")\n",
    "\n",
    "print(f\"\\nüìã FALLBACK (Rule-Based)\")\n",
    "print(f\"  Suggested weight: {sugg.suggested_weight:.2f} lbs\")\n",
    "print(f\"  Reason: {sugg.reason}\")\n",
    "print(f\"  Used when: ML fails, bench_press=True, or insufficient data\")\n",
    "\n",
    "print(f\"\\nüìà NEXT STEPS\")\n",
    "if len(history) < 12:\n",
    "    print(f\"  1. Log 4-8 more sessions ({12 - len(history)} to go)\")\n",
    "    print(f\"  2. Run: python -m src.cli refresh-calibration\")\n",
    "    print(f\"  3. Better calibration = more accurate predictions\")\n",
    "else:\n",
    "    print(f\"  1. Continue logging sessions\")\n",
    "    print(f\"  2. Periodically rerun calibration (every 10 sessions)\")\n",
    "    print(f\"  3. Monitor calibration coefficients (a, b) for convergence\")\n",
    "\n",
    "print(f\"\\nüíæ PERSISTENCE\")\n",
    "print(f\"  ‚Ä¢ JSON: users/User2/personalization.json (cached + on-disk)\")\n",
    "print(f\"  ‚Ä¢ SQLite: data/user_data.db (audit log)\")\n",
    "print(f\"  ‚Ä¢ Pickle: models/compounds/squat_model.pkl (global model)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
